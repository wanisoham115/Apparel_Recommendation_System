{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'C:/Users/wanis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(base_dir, 'new train')\n",
    "validation_dir = os.path.join(base_dir, 'new validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 15\n",
    "epochs = 20\n",
    "img_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications.vgg16 import VGG16\n",
    "# model=VGG16(include_top=False , weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cnn model\n",
    "def define_model():\n",
    "\t# load model\n",
    "\tmodel = VGG16(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))\n",
    "\t# model = load_model('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "\t# mark loaded layers as not trainable\n",
    "\tfor layer in model.layers:\n",
    "\t\tlayer.trainable = False\n",
    "\t# add new classifier layers\n",
    "\tflat1 = Flatten()(model.layers[-1].output)\n",
    "\tclass1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "#\toutput = Dense(5, activation='sigmoid')(class1)\n",
    "\toutput = Dense(7, activation='softmax')(class1)\n",
    "\t# define new model\n",
    "\tmodel = Model(inputs=model.inputs, outputs=output)\n",
    "\t# compile model\n",
    "#\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\topt = tf.keras.optimizers.RMSprop(lr=0.0001)\n",
    "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\t\n",
    "\t# plot accuracy\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([min(plt.ylim()),1])\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\t\n",
    "\t# plot loss\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Cross Entropy')\n",
    "    plt.ylim([0,max(plt.ylim())])\n",
    "    plt.title('Training and Validation Loss')\n",
    "\t\n",
    "\t# save plot to file\n",
    "    filename = 'vgg_b50e5'\n",
    "    plt.savefig(filename + '_plot.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# create data generator\n",
    "\tdatagen = ImageDataGenerator(featurewise_center=True)\n",
    "\t# specify imagenet mean values for centering\n",
    "\tdatagen.mean = [123.68, 116.779, 103.939]\n",
    "\t# prepare iterator\n",
    "\ttrain_it = datagen.flow_from_directory(train_dir,\n",
    "\t\tclass_mode='categorical', batch_size=batch_size, target_size=(img_size, img_size))\n",
    "\tvalidate_it = datagen.flow_from_directory(validation_dir,\n",
    "\t\tclass_mode='categorical', batch_size=batch_size, target_size=(img_size, img_size))\n",
    "\t# fit model\n",
    "\thistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "\t\tvalidation_data=validate_it, validation_steps=len(validate_it), epochs=epochs, verbose=1)\n",
    "\t# evaluate model\n",
    "\tacc = model.evaluate_generator(validate_it, steps=len(validate_it), verbose=0)\n",
    "\tacc = np.array(acc)\n",
    "\tprint(acc[1]*100)    \n",
    "    # save model\n",
    "\tmodel.save('C:/Users/wanis/final_model_700_7_softmax_bcross_20.h5')\n",
    "\tprint('Model saved as \"final_model_700_7_softmax_bcross_20.h5\"')\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wanis\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 700 images belonging to 7 classes.\n",
      "Found 140 images belonging to 7 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wanis\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "35/35 [==============================] - 209s 6s/step - loss: 0.7634 - accuracy: 0.6843 - val_loss: 0.2627 - val_accuracy: 0.8786\n",
      "Epoch 2/2\n",
      "35/35 [==============================] - 214s 6s/step - loss: 0.0795 - accuracy: 0.9729 - val_loss: 0.2349 - val_accuracy: 0.8857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wanis\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.57142925262451\n",
      "Model saved as \"final_model_700_7_softmax_bcross_20.h5\"\n"
     ]
    }
   ],
   "source": [
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "######\n",
    "## Extract Features:\n",
    "# model_feature = load_model('VGG16.h5')\n",
    "model_feature = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "model_feature.summary()\n",
    "\n",
    "import pandas as pd\n",
    "train_img = os.listdir(train_dir)\n",
    "images = []\n",
    "vgg16_feature_list = []\n",
    "label = []\n",
    "# print(train_img)\n",
    "# exit()\n",
    "for folder in train_img:\n",
    "#    print(folder)\n",
    "    for filename in os.listdir('new train/'+folder):\n",
    "        label.append(folder)\n",
    "#        print('new train/'+folder+'/'+filename)\n",
    "#        im = os.path.join('train',filename)\n",
    "        img_path = 'new train/'+folder+'/'+filename\n",
    "        images.append(img_path)\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img_data = image.img_to_array(img)\n",
    "        img_data = np.expand_dims(img_data, axis=0)\n",
    "        img_data = preprocess_input(img_data)\n",
    "\n",
    "        vgg16_feature = model_feature.predict(img_data)\n",
    "        vgg16_feature_np = np.array(vgg16_feature)\n",
    "        vgg16_feature_list.append(vgg16_feature_np.flatten())\n",
    "        \n",
    "vgg16_feature_list_np = np.array(vgg16_feature_list)\n",
    "\n",
    "df_feature = pd.DataFrame(list(zip(images,vgg16_feature_list_np,label)),columns= ['img_path','feature_vector','label'])\n",
    "\n",
    "df_feature.to_pickle('data feature 700')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 700 images belonging to 7 classes.\n",
      "Class labels:  {'blazer_men': 0, 'blazer_women': 1, 'dress': 2, 'hoodie': 3, 'jeans_men': 4, 'jeans_women': 5, 'shorts': 6}\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def get_labels():\n",
    "\tdatagen = ImageDataGenerator(featurewise_center=True)\n",
    "\t\n",
    "\ttrain_it = datagen.flow_from_directory(train_dir,class_mode='categorical', batch_size=batch_size, target_size=(img_size, img_size))\n",
    "#\ty_true_labels = train_it.classes\n",
    "\tlabel_map = (train_it.class_indices)\n",
    "\tprint('Class labels: ',label_map)\n",
    "\n",
    "get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Resize images\n",
    "path = \"C:/Users/wanis/new train\"\n",
    "folder = os.listdir(path)\n",
    "\n",
    "path2 = \"C:/Users/wanis/v4/static/new train\"\n",
    "\n",
    "def resize():\n",
    "\tfor one in folder:\n",
    "\t    dirs = os.listdir(path+'/'+one)\n",
    "\t    for item in dirs:\n",
    "\t       if os.path.isfile(path+'/'+one+'/'+item):\n",
    "\t           im = Image.open(path+'/'+one+'/'+item)\n",
    "\t           \n",
    "\t           imResize = im.resize((200,300), Image.ANTIALIAS)\n",
    "\t           imResize.save(path2+'/'+one+'/'+item, 'JPEG', quality=90)\n",
    "\n",
    "resize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature vectors of train data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "base_dir = 'C:/Users/wanis'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'new train')\n",
    "validation_dir = os.path.join(base_dir, 'new validation')\n",
    "\n",
    "train_img = os.listdir(train_dir)\n",
    "images = []\n",
    "vgg16_feature_list = []\n",
    "label = []\n",
    "\n",
    "model_feature = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "# model_feature = load_model('VGG16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in train_img:\n",
    "#    print(folder)\n",
    "    for filename in os.listdir(base_dir+'/new train/'+folder):\n",
    "        label.append(folder)\n",
    "#        print('train/'+folder+'/'+filename)\n",
    "#        im = os.path.join('train',filename)\n",
    "        img_path = base_dir+'/new train/'+folder+'/'+filename\n",
    "        images.append(img_path)\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img_data = image.img_to_array(img)\n",
    "        img_data = np.expand_dims(img_data, axis=0)\n",
    "        img_data = preprocess_input(img_data)\n",
    "\n",
    "        vgg16_feature = model_feature.predict(img_data)\n",
    "        vgg16_feature_np = np.array(vgg16_feature)\n",
    "        vgg16_feature_list.append(vgg16_feature_np.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_feature_list_np = np.array(vgg16_feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature = pd.DataFrame(list(zip(images,vgg16_feature_list_np,label)),columns= ['img_path','feature_vector','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature.to_pickle('data feature 700')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
